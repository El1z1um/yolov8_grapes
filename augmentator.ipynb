{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import shutil\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leer_anotaciones_yolo(anotacion_txt):\n",
    "    with open(anotacion_txt, \"r\") as f:\n",
    "        lineas = f.readlines()\n",
    "    \n",
    "    anotaciones = []\n",
    "    for linea in lineas:\n",
    "        anotaciones.append([float(i) for i in linea.strip().split(\" \")])\n",
    "        \n",
    "    return anotaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def guardar_anotaciones_yolo(anotaciones, archivo_salida):\n",
    "    with open(archivo_salida, \"w\") as f:\n",
    "        for anotacion in anotaciones:\n",
    "            linea = \" \".join(str(i) for i in anotacion)\n",
    "            f.write(linea + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aplicar_transformacion(img, anotaciones, transform):\n",
    "    labels = [x[0] for x in anotaciones]\n",
    "    bboxes = [x[1:] for x in anotaciones]\n",
    "    \n",
    "    resultado = transform(image=img, bboxes=bboxes, labels=labels)\n",
    "    img_transformada = resultado[\"image\"]\n",
    "    anotaciones_transformadas = [\n",
    "        [label, *box] for label, box in zip(resultado['labels'], resultado['bboxes']) if box[2] > 0 and box[3] > 0\n",
    "    ]\n",
    "    \n",
    "    return img_transformada, anotaciones_transformadas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aumentar_dataset(input_folder, output_folder, num_output_images=1000):\n",
    "    transform = A.Compose([\n",
    "        A.Resize(640, 640),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.RandomRotate90(p=0.5),\n",
    "        A.Rotate(limit=10, p=0.5),\n",
    "        A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.1, rotate_limit=45, p=0.5),\n",
    "        A.RandomBrightnessContrast(brightness_limit=(-0.1, 0.1), contrast_limit=(0.3, 0.5), p=0.5),\n",
    "        A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=20, p=0.5),\n",
    "        A.RandomScale(scale_limit=0.2, p=0.5),\n",
    "        A.GaussNoise(var_limit=(10, 50), mean=0, p=0.5),\n",
    "        A.GaussianBlur(p=0.5),\n",
    "        A.MotionBlur(p=0.5),\n",
    "        A.CLAHE(clip_limit=4.0, p=0.5),\n",
    "        A.Cutout(num_holes=8, max_h_size=16, max_w_size=16, p=0.5),\n",
    "    ], bbox_params=A.BboxParams(format='yolo', label_fields=['labels'], min_area=0.001, min_visibility=0.001))\n",
    "\n",
    "\n",
    "    transform_original = A.Compose([\n",
    "        A.Resize(640, 640)\n",
    "    ], bbox_params=A.BboxParams(format='yolo', label_fields=['labels'], min_area=0.001, min_visibility=0.001))\n",
    "\n",
    "\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    all_files = os.listdir(input_folder)\n",
    "    img_files = [f for f in all_files if f.endswith(\".jpg\")]\n",
    "    num_files = len(img_files)\n",
    "\n",
    "    for img_name in img_files:\n",
    "        img_path = os.path.join(input_folder, img_name)\n",
    "        txt_path = os.path.join(input_folder, f\"{img_name[:-4]}.txt\")\n",
    "\n",
    "        # Verifica si existe el archivo .txt antes de continuar\n",
    "        if not os.path.exists(txt_path):\n",
    "            continue\n",
    "        \n",
    "        img = cv2.imread(img_path)\n",
    "        anotaciones = leer_anotaciones_yolo(txt_path)\n",
    "\n",
    "        # Aplica la transformación de redimensionamiento a la imagen original y sus anotaciones\n",
    "        img_resized, anotaciones_resized = aplicar_transformacion(img, anotaciones, transform_original)\n",
    "\n",
    "        # Guarda la imagen original redimensionada y su archivo de anotaciones en el directorio de salida\n",
    "        cv2.imwrite(os.path.join(output_folder, img_name), img_resized)\n",
    "        guardar_anotaciones_yolo(anotaciones_resized, os.path.join(output_folder, f\"{img_name[:-4]}.txt\"))\n",
    "       \n",
    "        # Bucle para generar imágenes aumentadas y guardarlas en el directorio de salida\n",
    "        for i in range(num_output_images // num_files):\n",
    "            img_aug, anotaciones_aug = aplicar_transformacion(img, anotaciones, transform)\n",
    "\n",
    "            new_img_name = f\"{img_name[:-4]}_aug_{i}.jpg\"\n",
    "            new_txt_name = f\"{img_name[:-4]}_aug_{i}.txt\"\n",
    "\n",
    "            cv2.imwrite(os.path.join(output_folder, new_img_name), img_aug)\n",
    "            guardar_anotaciones_yolo(anotaciones_aug, os.path.join(output_folder, new_txt_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Premature end of JPEG file\n",
      "Premature end of JPEG file\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m output_folder \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/Users/baudi/AI/practicas/grapes/augmented6\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m num_output_images \u001b[39m=\u001b[39m \u001b[39m10000\u001b[39m\n\u001b[0;32m----> 5\u001b[0m aumentar_dataset(input_folder, output_folder, num_output_images)\n",
      "Cell \u001b[0;32mIn[11], line 51\u001b[0m, in \u001b[0;36maumentar_dataset\u001b[0;34m(input_folder, output_folder, num_output_images)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[39m# Bucle para generar imágenes aumentadas y guardarlas en el directorio de salida\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_output_images \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m num_files):\n\u001b[0;32m---> 51\u001b[0m     img_aug, anotaciones_aug \u001b[39m=\u001b[39m aplicar_transformacion(img, anotaciones, transform)\n\u001b[1;32m     53\u001b[0m     new_img_name \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mimg_name[:\u001b[39m-\u001b[39m\u001b[39m4\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m_aug_\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m.jpg\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     54\u001b[0m     new_txt_name \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mimg_name[:\u001b[39m-\u001b[39m\u001b[39m4\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m_aug_\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m.txt\u001b[39m\u001b[39m\"\u001b[39m\n",
      "Cell \u001b[0;32mIn[4], line 5\u001b[0m, in \u001b[0;36maplicar_transformacion\u001b[0;34m(img, anotaciones, transform)\u001b[0m\n\u001b[1;32m      2\u001b[0m labels \u001b[39m=\u001b[39m [x[\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m anotaciones]\n\u001b[1;32m      3\u001b[0m bboxes \u001b[39m=\u001b[39m [x[\u001b[39m1\u001b[39m:] \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m anotaciones]\n\u001b[0;32m----> 5\u001b[0m resultado \u001b[39m=\u001b[39m transform(image\u001b[39m=\u001b[39;49mimg, bboxes\u001b[39m=\u001b[39;49mbboxes, labels\u001b[39m=\u001b[39;49mlabels)\n\u001b[1;32m      6\u001b[0m img_transformada \u001b[39m=\u001b[39m resultado[\u001b[39m\"\u001b[39m\u001b[39mimage\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m      7\u001b[0m anotaciones_transformadas \u001b[39m=\u001b[39m [\n\u001b[1;32m      8\u001b[0m     [label, \u001b[39m*\u001b[39mbox] \u001b[39mfor\u001b[39;00m label, box \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(resultado[\u001b[39m'\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m'\u001b[39m], resultado[\u001b[39m'\u001b[39m\u001b[39mbboxes\u001b[39m\u001b[39m'\u001b[39m]) \u001b[39mif\u001b[39;00m box[\u001b[39m2\u001b[39m] \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m box[\u001b[39m3\u001b[39m] \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m      9\u001b[0m ]\n",
      "File \u001b[0;32m~/miniconda3/envs/yolo_env/lib/python3.11/site-packages/albumentations/core/composition.py:205\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, force_apply, *args, **data)\u001b[0m\n\u001b[1;32m    202\u001b[0m     p\u001b[39m.\u001b[39mpreprocess(data)\n\u001b[1;32m    204\u001b[0m \u001b[39mfor\u001b[39;00m idx, t \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(transforms):\n\u001b[0;32m--> 205\u001b[0m     data \u001b[39m=\u001b[39m t(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mdata)\n\u001b[1;32m    207\u001b[0m     \u001b[39mif\u001b[39;00m check_each_transform:\n\u001b[1;32m    208\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_data_post_transform(data)\n",
      "File \u001b[0;32m~/miniconda3/envs/yolo_env/lib/python3.11/site-packages/albumentations/core/transforms_interface.py:109\u001b[0m, in \u001b[0;36mBasicTransform.__call__\u001b[0;34m(self, force_apply, *args, **kwargs)\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mall\u001b[39m(key \u001b[39min\u001b[39;00m kwargs \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtargets_as_params), \u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m requires \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    106\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtargets_as_params\n\u001b[1;32m    107\u001b[0m     )\n\u001b[1;32m    108\u001b[0m     targets_as_params \u001b[39m=\u001b[39m {k: kwargs[k] \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtargets_as_params}\n\u001b[0;32m--> 109\u001b[0m     params_dependent_on_targets \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_params_dependent_on_targets(targets_as_params)\n\u001b[1;32m    110\u001b[0m     params\u001b[39m.\u001b[39mupdate(params_dependent_on_targets)\n\u001b[1;32m    111\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdeterministic:\n",
      "File \u001b[0;32m~/miniconda3/envs/yolo_env/lib/python3.11/site-packages/albumentations/augmentations/transforms.py:1232\u001b[0m, in \u001b[0;36mGaussNoise.get_params_dependent_on_targets\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m   1229\u001b[0m sigma \u001b[39m=\u001b[39m var\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m0.5\u001b[39m\n\u001b[1;32m   1231\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mper_channel:\n\u001b[0;32m-> 1232\u001b[0m     gauss \u001b[39m=\u001b[39m random_utils\u001b[39m.\u001b[39;49mnormal(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmean, sigma, image\u001b[39m.\u001b[39;49mshape)\n\u001b[1;32m   1233\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1234\u001b[0m     gauss \u001b[39m=\u001b[39m random_utils\u001b[39m.\u001b[39mnormal(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmean, sigma, image\u001b[39m.\u001b[39mshape[:\u001b[39m2\u001b[39m])\n",
      "File \u001b[0;32m~/miniconda3/envs/yolo_env/lib/python3.11/site-packages/albumentations/random_utils.py:50\u001b[0m, in \u001b[0;36mnormal\u001b[0;34m(loc, scale, size, random_state)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[39mif\u001b[39;00m random_state \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     49\u001b[0m     random_state \u001b[39m=\u001b[39m get_random_state()\n\u001b[0;32m---> 50\u001b[0m \u001b[39mreturn\u001b[39;00m random_state\u001b[39m.\u001b[39;49mnormal(loc, scale, size)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "input_folder = \"/Users/baudi/AI/practicas/grapes/train_aug\"\n",
    "output_folder = \"/Users/baudi/AI/practicas/grapes/augmented6\"\n",
    "num_output_images = 10000\n",
    "\n",
    "aumentar_dataset(input_folder, output_folder, num_output_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import albumentations as A\n",
    "\n",
    "def mejorar_brillo_contraste(input_image_path, output_image_path):\n",
    "    # Define la transformación para ajustar el brillo y el contraste de la imagen\n",
    "    transform = A.Compose([\n",
    "        A.RandomBrightnessContrast(brightness_limit=(-0.1, 0.1), contrast_limit=(0.3, 0.5), p=1.0),\n",
    "        A.HueSaturationValue(sat_shift_limit=40, p=1.0),  # Aumenta la diferencia de color\n",
    "        A.ImageCompression(quality_lower=60, quality_upper=100, p=1.0),  # Mejora los detalles de la imagen\n",
    "\n",
    "    ])\n",
    "\n",
    "    # Lee la imagen de entrada\n",
    "    img = cv2.imread(input_image_path)\n",
    "\n",
    "    # Aplica la transformación de brillo y contraste a la imagen\n",
    "    img_transformed = transform(image=img)[\"image\"]\n",
    "\n",
    "    # Guarda la imagen mejorada en el directorio de salida\n",
    "    cv2.imwrite(output_image_path, img_transformed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Ejemplo de uso de la función:\n",
    "input_folder = \"/Users/baudi/AI/practicas/grapes/test\"\n",
    "output_folder = \"/Users/baudi/AI/practicas/grapes/test_improved\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "all_files = os.listdir(input_folder)\n",
    "img_files = [f for f in all_files if f.endswith(\".jpg\")]\n",
    "\n",
    "for img_name in img_files:\n",
    "    input_image_path = os.path.join(input_folder, img_name)\n",
    "    output_image_path = os.path.join(output_folder, img_name)\n",
    "    mejorar_brillo_contraste(input_image_path, output_image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
